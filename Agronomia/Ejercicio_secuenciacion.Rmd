---
title: "Análisis de secuenciacion de practica"
output: html_notebook
---

# SECUENCIACIÓN METAGENOMICA DADA2
```{r}
library(dada2)
library(tidyverse)
library(dplyr)
```

```{r}
# Determinar el camino al directorio donde estan las muestras:

path <- "~/CursoR/CursoRgit/Agronomia/Secuenciacion_agro"

list.files(path)

# Ahora se separan las muestras en objetos entre forward y reverse reads:

# Forward
fnFs <- sort(list.files(path,pattern="_R1.fastq.gz", full.names = TRUE))

# Reverse
fnRs <- sort(list.files(path,pattern="_R2.fastq.gz", full.names = TRUE))

sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`,1) 
```

### Revision de los perfiles de calidad

```{r}
# forward
plotQualityProfile(fnFs[1:6]) 

# reverse
plotQualityProfile(fnRs[1:6])
```

### Filtrar y cortar 

Primero crearemos una nueva carpeta para nuestras secuencias filtradas, asi como un nombre para los archivos .fastq que obtengamos.

```{r}
# Guardando el camino a nuestras muestras filtradas en un objeto nuevo

filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))

filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))

# Asignando los nombres de las muestras a nuestros nuevos objetos
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```

__Explicacion de los parametros de filtrado y corte__

En cuanto al error esperado maxEE se opto por elegir (5,5), con el objetivo de ser menos estrictos en cuanto a los errores esperados y asi evitar perder muchas muestras.

```{r}
out <- filterAndTrim(fnFs, filtFs, # forward reads
                     fnRs, filtRs, # reverse reads
                     truncLen=c(140,140), # truncado o corte
                     maxN=0, # remover Ns NUNCA SE MODIFICA
                     maxEE=c(5,5), # error esperado
                     truncQ=2, # quality score
                     rm.phix=TRUE, compress=TRUE, # defaults
                     multithread=FALSE) # En windows multithread=FALSE
```

```{r}
# Se guarda el progreso:

write.csv(out, "~/CursoR/CursoRgit/Agronomia/Materiales/Conteo_reads2.csv") 

#### Por si queremos retomar despues de filtrar ####

## Nuevo Camino
path2 <- "~/CursoR/CursoRgit/Agronomia/Secuenciacion_agro/filtered/"

# Forward
filtFs <- sort(list.files(path2,pattern="_F_filt.fastq.gz", full.names = TRUE))

# Reverse
filtRs <- sort(list.files(path2,pattern="_R_filt.fastq.gz", full.names = TRUE))
```

### Tasas de error

```{r}
# Forward
errF <- learnErrors(filtFs, multithread=TRUE)
save(errF,file = "errF.RData")

# Reverse
errR <- learnErrors(filtRs, multithread=TRUE)
save(errR,file = "errR.RData") 

# Para volver a subir los archivos nuevamente se utiliza:
load("errF.RData")
load("errR.RData")

# Plot error rates
plotErrors(errF, nominalQ = TRUE)
plotErrors(errR, nominalQ = TRUE)
```

### Inferencia de las muestras

```{r}
# Forward
dadaFs_nopool <- dada(filtFs, err=errF, multithread=TRUE,
                      pool = FALSE)
save(dadaFs_nopool, file = "dadaFs_nopool.RData")

load("dadaFs_nopool.RData")

# Reverse
dadaRs_nopool <- dada(filtRs, err=errR, multithread=TRUE,
                      pool = FALSE)
save(dadaRs_nopool, file = "dadaRs_nopool.RData")

load("dadaRs_nopool.RData")
```

### Uniendo las lecturas forward y reverse

```{r}
mergers <- mergePairs(dadaFs_nopool, filtFs, dadaRs_nopool, filtRs, verbose = TRUE)
save(mergers, file = "mergers.RData")

# parametros opcionales
mergers <- mergePairs(dadaFs_nopool, filtFs, dadaRs_nopool, filtRs, 
                      verbose = TRUE,
                      minOverlap = 10, # tratar para ver si se incrementan las uniones
                      maxMismatch = 2, # el parametro default es 0, por lo que tiene que ser una union perfecta, no poner mas de 5 
                      justConcatenate = TRUE, # une forward y pone NNNNX10 y luego une al reverse
                      returnRejects = TRUE) # nos muestra una tabla de reads rechazadas al momento de union, para ver si salen muchos mismatches incrementar el mismatch o si se estan uniendo muy poco cambiar en overlap. Se comenzaria con usar este parametro para ver que estamos perdiendo luego usamos mismatch, overlap y al final concatenate.

# Podemos estar perdiendo muchas muestras porque no estan limpias las muestras y tienen mala calidad o pueden venir con primers.

load("mergers.RData") 
```

### Hacer tablas de secuencias

```{r}
## Sequence table

seqtab <- makeSequenceTable(mergers)
dim(seqtab) # numero de muestras x numero de ASVs

# Checar la longitud de todas las secuencias
table(nchar(getSequences(seqtab)))
```

### Quitar quimeras

```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method = "consensus",
                                    multithread = TRUE, verbose = TRUE)
save(seqtab.nochim, file = "seq_conteos.RData")

# Se identificaron 197 bimeras de 954 secuencias.

# Basados en esto el 20% de mis secuencias son quimeras

## Comparar esta tabla con la original que incluye quimeras
dim(seqtab.nochim)
sum(seqtab.nochim)/sum(seqtab) # se mantuvieron un 82% de secuencias no quimericas

load("seq_conteos.RData")

```

### Seguimiento del proceso

```{r}
out <- read.csv("~/CursoR/CursoRgit/Agronomia/Materiales/Conteo_reads2.csv")

# Primero crearemos una funcion
getN <- function(x) sum(getUniques(x))

# Creamos una nueva tabla llamada track
track <- cbind(out, # Paso 1: filtrado y corte
               sapply(dadaFs_nopool, getN), 
               sapply(dadaRs_nopool, getN), # Paso 3: denoising
               sapply(mergers, getN), # Paso 4: unir muestras
               rowSums(seqtab.nochim)) # Paso 5: quitar quimeras

# Nombramos nuestras filas y columnas
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")

#Guardamos esta tabla
write.csv(track, "~/CursoR/CursoRgit/Agronomia/Materiales/Abundancias.csv")
```

### Asignar taxonomia

```{r}
# Se crea la tabla de taxonomia
taxa <- assignTaxonomy(seqtab.nochim, "~/CursoR/CursoRgit/Secuenciacion/SILVA/silva_nr99_v138.1_train_set.fa.gz", multithread = TRUE)

# Se añaden especies a la tabla
taxa <- addSpecies(taxa, "~/CursoR/CursoRgit/Secuenciacion/SILVA/silva_species_assignment_v138.1.fa.gz")

save(taxa, file = "taxa.RData")

write.csv(taxa, "~/CursoR/CursoRgit/Agronomia/Materiales/taxa.csv")
``` 

# ANÁLISIS DE PHYLOSEQ

## Librerias y datos
```{r}
library(phyloseq)

# Paso 1: Subir tablas de dada
load("taxa.RData") # identificacion taxonomicas
load("seq_conteos.RData") # abundancia ASVs

# Paso 2: metadatos
metadatos <- data.frame(Tratamiento = c("Tratado", "Testigo", "Testigo","Tratado", "Tratado", "Testigo"), Muestreo = c(rep("Primero",2),rep("Segundo",2), rep("Tercero",2)))
                        
row.names(metadatos) <- c("M1", "M5", "M7", "M12", "M15", "M16")

# Paso 3: Renombrar muestras no es necesario correrlo
sample_names <- c("M1", "M12", "M15", "M16", "M5", "M7")
row.names(seqtab.nochim) <- sample_names

# Paso 4: Cambiar nombres de secuencias
rando <- function(n = 5000) {
  a <- do.call(paste0, replicate(5, sample(LETTERS, n, TRUE), FALSE))
  paste0(a, sprintf("%04d", sample(9999, n, TRUE)), sample(LETTERS, n, TRUE))
}

dim(seqtab.nochim) # 757
seqnames <- rando(757) # entre parentesis va el resultado de la funcion anterior

# Guardar las secuencias en otro objeto antes de borrarlas
Secuencias <- colnames(seqtab.nochim)
write.csv(Secuencias, "~/CursoR/CursoRgit/Agronomia/Materiales/Secuencias.csv")

# Cambiando nombre con codigo
colnames(seqtab.nochim) <- seqnames

write.csv(seqtab.nochim, "~/CursoR/CursoRgit/Agronomia/Materiales/Tabla_ASV.csv")
# Paso 5: Cambiar el nombre a las secuencias en taxa, tabla de asignacion taxonomica

# Para que nuestra tablas se puedan "unir" y analizarse juntas dentro del objeto de phyloseq necesitamos tener los mismos nombres para nuestras variables. Por ello ahora tenemos que cambiar los nombres de las filas de nuestra tabla de taxa (que son las secuencias que acabamos de quitar) al codigo o nombre que le dimos en la parte de arriba

row.names(taxa) <- seqnames

write.csv(taxa, "~/CursoR/CursoRgit/Agronomia/Materiales/taxa.csv")

# Paso 6: PASO FINAL, ahora si todo listo para armar nuestro objeto y usarlo para todo tipo de analisis:

Bio <- phyloseq(otu_table(seqtab.nochim,
                               taxa_are_rows = FALSE), 
                     sample_data(metadatos),
                     tax_table(taxa))

# y no se olviden de guardarlo
save(Bio, file = "Bio.RData")
```

# HERRAMIENTAS DE PHYLOSEQ

# Introduccion

Como vimos antes de irnos phyloseq nos ayuda a integrar todos nuestros datos en un objeto para poder analizarlo. La clase de hoy vamos a ver como phyloseq nos deja modificar estos objetos para visualizarlos mejor y seguir con los diferentes tipo de analisis usando los datos de vid.
 
```{r}
load("Bio.RData") # siempre se empieza con el objeto de phyloseq, por si queremos volver a retomar
```

# Las primeras visualizaciones de nuestros datos

Si bien con estos datos ya podemos realizar grafico que nos acercan mas al analisis el hecho es de que siempre es comvenenientre pre-procesar los datos antes de cualquier grafico. Para ello phyloseq nos ofrece varias herramientas:

# Preproccesamiento de datos

## Filtrado

```{r}
# Porque tres muestras?

PS_filtered <- filter_taxa(Bio, # objeto 
                           function(OTU) sum(OTU) > 2, # condicion o funcion
                           TRUE) # cortar
# este es un proceso de filtrado por numero de muestras 
# de 757 me dejo con 635

# Remover taxa no identificada
PS_filtered <- subset_taxa(PS_filtered, # objeto 
                           !is.na(Phylum)) # condicion que se aplica para que de los que no tengan nada en phylum me los quite
# me dejo con 625
```

### Prune vs subset

```{r}
# usando datos de la tabla de taxa
Actino <- subset_taxa(Bio, # objeto
                      Phylum=="Actinobacteriota") # la condicion puede ser cualquier nivel de la jerarquia taxonomica

# usando abundancias quitar muestras
Actino <- prune_samples(sample_sums(Actino)>=50, # condicion que las que sean menor a 50 me las va a quitar
                        Actino) # objeto
```

# Union o merge

```{r}
# No es necesario realizarlo
```

## Abundancia relativa

DADA2 nos da abundancias absolutas las cuales pasamos a nuestro objeto de phyloseq. La abundancia abdoluta es el conteo TOTAL de las especies e individuos dentro de cada especie

La abundancia relativa en cambio normaliza nuestras muestras para poder compararlas entre si. Para ello usa proporciones siendo 1 el 100% de nuestro conteo por muestras. De esta manera podemos comparar la composicion de nuestras muestras aunque no tengamos valores totales o absolutos iguales.

Para transformar de abundancia absoluta a relativa o cualquier otro tipo de calculo para nuestras muestras se usa la siguiente funcion en phyloseq:

```{r}
Psoil_rel <- transform_sample_counts(PS_filtered, # objeto a transformar
                                     function(x) x/sum(x)) # x es mi conteo
```

# Reexploramos graficos

```{r}
# 1. Graficos
Top_phyla <- tax_glom(Psoil_rel,taxrank = "Phylum", NArm = FALSE)
Top_phyla <- prune_taxa(names(sort(taxa_sums(Top_phyla), TRUE)[1:10]), #cond
                        Top_phyla) # objeto que voy a modificar

plot_bar(Top_phyla, fill = "Phylum")
plot_heatmap(Top_phyla, taxa.label = "Phylum")
```

# DIVERSIDAD ALFA

```{r}
# Se pusieron las librerias para el analisis de diversidad alfa y beta pero en este caso no se analizará por que se requiere solamente verificar la abundancia.

# Librerias
library(phyloseq)
library(ggplot2)
library(RColorBrewer)
library(tidyverse)
library(dplyr)
library(car)
library(breakaway) # chao-bunge
library(microbiome)
library(agricolae)

# DATA
load("Bio.RData")
```

# ANÁLISIS TAXA

```{r}
## Librerías ##

library(phyloseq)
library(tidyverse)
library(dplyr)
library(RColorBrewer)
library(pheatmap) # Heatmaps
library(microbiome)
library(ggsignif)
library(scales) # Modificar escalas
library(car)
library(wesanderson)

# DATA 
load("Bio.RData")

```

Este analisis no cumple con un proceso en específico y en realidad es exploratorio. Para ello necesitamos visualizar nuestros datos, o sea, hacer variedad de gráficos y de ahí se elige a cuales grupos vale la pena hacer análisis taxonómico 

# 1. Visualizar a nivel de Phylum

## Heatmap

```{r}

Phyla_fun <- tax_glom(Bio, taxrank = "Phylum", NArm = FALSE)

## Extraer datos del objeto phyloseq

OTU_matrix <- as.data.frame(Phyla_fun@otu_table)
Tax_matrix <- as.data.frame(Phyla_fun@tax_table)


# Renombramos las columnas de nuestras abundancias con el phylum de la tabla taxa

colnames(OTU_matrix) <- Tax_matrix$Phylum 

# Quitar phylum desconocido (SOLO DATOS DE VID). Se quitaron las columnas con datos NA

OTU_matrix <- OTU_matrix[, -c(7)]

# crear matriz a partir de OTU siempre se debe usar en vez de tabla porque solo necesitamos valores numericos
Phyla_matrix <- as.matrix(t(OTU_matrix)) # las muestras deben quedar como columnas y las filas como phylum por eso se utiliza transpose(t)

```

# Procesamiento de datos 

Este proceso es específico para cada set de datos. Usualmente los heatmaps siempre van de mayor a menor, así que ese paso siempre se realiza, pero el resto consta de de ordenar las muestras y renombrar variables.

```{r}

Phyla_matrix <- Phyla_matrix[order(Phyla_matrix[,1], # se escoge la columna 1para que me empiece a ordenar de mayor a menor
                                   decreasing = TRUE),] # Ordenar de mayor a menor 

# Cambiar el orden de las muestras

sorder <- c("M1", "M5", "M12", "M7", "M15","M16")

Phyla_matrix <- Phyla_matrix[,sorder]

```

## Usando el paquete Pheatmap para realizar heatmaps de análisis taxonómico 

La funcion default de pheatmap es que automaticamente te reacomoda (cluster) tus filas y columnas de acuerdo a como cree que estan mas relacionadas las variables; es decir las agrupa. Esta funcion suele ser util cuando haces heatmaps de genes ya que te permite ver como se activan o apagan en conjunto y si hay "clusters" de genes relacionados. Pero en nuestro caso arruino todo el pre-procesamiento previo que nosotros le dimos por lo que tenemos que quitarle ese default.

```{r}
pheatmap(Phyla_matrix,
         cluster_rows = FALSE, cluster_cols = FALSE) # quitar clusters

```


```{r}
## Funcion especificamente para separar nuestros datos en secciones

quantile_breaks <- function(xs, n = 10) {
  breaks <- quantile(xs, probs = seq(0, 1, length.out = n))
  breaks[!duplicated(breaks)]
} # recuerden que la funcion nunca se cambia de nombre(copien y peguen siempre entre documentos)

mat_breaks <- quantile_breaks(Phyla_matrix, # es la matriz
                              n = 10) # el default es 10 pero se puede poner el numero de cortes que quiero a mis datos

pheatmap(Phyla_matrix,
         cluster_rows = FALSE, cluster_cols = FALSE,
         scale = "none", 
         color = colorRampPalette(c("snow2","lightskyblue1","plum3","magenta4","steelblue4","black"))(6),
         breaks = mat_breaks,
         fontsize = 10, 
         angle_col = 0,
         fontsize_col = 10,
         gaps_col = c(2,4),
         fontsize_row = 8,
         main = "Análisis taxonómico por Phylum",
         labels_col = c("Tratado 1ro", "Testigo 1ro","Tratado 2do", "Testigo 2do", "Tratado 3ro", "Testigo 3ro"))
```

## Grafico de Barras

Se acuerdan que al ver las funciones que nos daba phyloseq vimos como hacer graficos de barras? Pues bueno ahora vamos a aprender a hacerlos bonitos:

### Pre-procesamiento de datos

```{r}
# Recuerden que este tipo de graficos siempre se hacen con abundancias relativas.

Psoil_rel <- transform_sample_counts(Bio, # objeto a transformar
                                   function(x) x/sum(x)) # x es mi conteo

# Otra vez juntar phylums
Top_phyla <- tax_glom(Psoil_rel, taxrank = "Phylum", NArm = FALSE)

# Seleccionar solo los valores top
Top_phyla <- prune_taxa(names(sort(taxa_sums(Top_phyla), TRUE)[1:10]),
                        Top_phyla)
```

### El grafico

Usando la funcion plot_composition del paquete microbiome

```{r}
# Grafico base
plot_composition(Top_phyla, # objeto en valores relativos
                 plot.type = "barplot", # tipo de grafico tambien hace heatmap
                 )

# Ahora mas bonito

plot_composition(Top_phyla,plot.type = "barplot")+
  theme_bw()+
  scale_fill_brewer(palette = "Spectral", name = "Phylum",
                    labels=c("Acidobacteriota", "Proteobacteria", "Firmicutes", "Actinobacteriota", "Chloroflexi", "WPS-2","NA","Planctomycetota", "Nitrospirota","Gemmatimonadota"))+
  guides(x=guide_axis(angle=90))
  
```

Si bien este grafico ya es hermoso, la forma mas simple de representar abundancia relativa es con porcentajes. Asi que les voy a ensenar la formula de scales te modifica etso facilmente

```{r}
plot_composition(Top_phyla,plot.type = "barplot")+
  theme_bw()+
  ggtitle("Abundancias relativas a nivel Phylum")+
  theme(plot.title = element_text(hjust = 0.5, size = 15, face = "bold"))+
  xlab("Muestras")+
  ylab("Abundancia")+
  scale_fill_brewer(palette = "Spectral", name = "Phylum",
                     labels=c("Acidobacteriota", "Proteobacteria", "Firmicutes", "Actinobacteriota", "Chloroflexi", "WPS-2","NA","Planctomycetota","Nitrospirota","Gemmatimonadota"))+
  scale_x_discrete(labels=c("Tratado 1°", "Tratado 2°", "Tratado 3°","Testigo 3°", "Testigo 1°", "Testigo 2°"))+
  guides(x=guide_axis(angle=0))+
  scale_y_continuous(breaks = pretty_breaks(n = 10),# numero de separaciones
                     labels = scales::percent)# representadas en %

```

Usando estos dos graficos que pueden conclur de sus datos?
Hay algun phylum que crean que vale la pena revisar a detalle? 

Proteocateria y actinobacteriota por abundancias
Chloroflexi y firmicutes por diferencias entre tratamientos

Si bien ya les ensene a presentar graficos bonitos y definitivamente cualquiera de estos graficos podrian incluirlo en un reporte, la visualizacion tambien nos permite darnos cuenta si existen ciertos patrones en abundancia. De esta manera podemos seleccionar alguno de estos grupos y verlos en la lupa de una manera mas minuciosa.

Por ejemplo, yo de mis datos podria decir que dada la dominancia que tiene Ascomycota tal vez vale la pena revisarla minuciosamente. Sin embargo, el heatmap no nos mostro si habian diferencias entre plantas o tratamientos (porque tal vez no las hay?) por lo que hacer varios loops de analisis estadistico seria muy util para elegirlos

## Preprocesamiento
```{r}

## Preprocesamiento no se corre al menos que hayas corrido lo anterior de arriba
Phyla_fun <- tax_glom(Bio, taxrank = "Phylum", NArm = FALSE)

## Extraer datos del objeto phyloseq

OTU_matrix <- as.data.frame(Phyla_fun@otu_table)
Tax_matrix <- as.data.frame(Phyla_fun@tax_table)

## Extract metadata
metadatos <- as.data.frame(Phyla_fun@sam_data)

## Renombramos las columnas de nuestras abundancias con el phylum de la tabla de taxa
colnames(OTU_matrix) <- Tax_matrix$Phylum 
OTU_matrix <- OTU_matrix[,-7]

# Se corre solo esto si ya tenemos lo que se corrio antes de los heatmaps
Bio_phyla <- cbind(metadatos,OTU_matrix)
```

## Normalizacion
```{r}
## shapiro test
for(i in 3:ncol(Bio_phyla)){
  shapiro <- shapiro.test(Bio_phyla[,i])
  normal <- ifelse(shapiro[["p.value"]]>0.05, "YES", "NO")
  print(c(i,normal))
} # vamos a quitar de la 14 a 21, porque no son normales y tienen una baja abundancia

### Normalizar phylums ###

# Seleccionamos tabla los phylums que queremos normalizar

# Norm_vid <- vid_phyla[,c(24:26,28,30:34,37)]

# Transformamos con log

# for(i in 1:ncol(Norm_vid)){
  #Norm_vid[,i] <- abs(log10(Norm_vid[,i]+1)) 
#}

# for(i in 1:ncol(Norm_vid)){
#  shapiro <- shapiro.test(Norm_vid[,i])
#  normal <- ifelse(shapiro[["p.value"]]>0.05, "YES", "NO")
#  print(c(i,normal))
#}

# vid_stats <- cbind(vid_phyla[,-c(10,15,24:28,30:34,37:40)],Norm_vid) # se unen las tablas


# concluimos que casi la mitad de nuestros phylums son normales, unos no se pudieron normalizar porque tienen muchos ceros

# Tabla final

Norm_bio <- Bio_phyla[,-c(14:21)] # estoy quitando columna por baja abundancia

for(i in 3:ncol(Norm_bio)){
  shapiro <- shapiro.test(Norm_bio[,i])
  normal <- ifelse(shapiro[["p.value"]]>0.05, "YES", "NO")
  print(c(i,normal))
} 

### For loop de t.test ###

# Paso 1. Tabla vacia
phyla_pvalues <- data.frame(Tratamiento = rep(NA, 11),
                            Muestreo = rep(NA,11)) # contar el numero de variables 

# vamos hacer dos t tests uno para cada variable por eso dos columnas

# Paso 1.5:
objeto_T <- t.test(Proteobacteria ~ Tratamiento, data = Norm_bio)
# De aqui vimos como llamar al p value
# objeto_T[["p.value"]]

# ver si se pueden meter valores por columnas:
 prueba <- aov(Norm_bio[,3] ~ Muestreo, data = Norm_bio)
 Anova(prueba, type = 2) 

# Paso 2: for loop
for(i in 3:ncol(Norm_bio)){
  T_trat <- t.test(Norm_bio[,i]~Tratamiento, data=Norm_bio)
  M_trat <- Anova(aov(Norm_bio[,i]~Muestreo, data=Norm_bio))
  j <- i-2 # esto es para que empiece a llenar desde la fila 1 
  phyla_pvalues$Tratamiento[j] <- T_trat[["p.value"]]
  phyla_pvalues$Muestreo[j] <- M_trat$`Pr(>F)`[1]
}
 
row.names(phyla_pvalues) <- colnames(Norm_bio[3:13])

# Se guarda esta tabla
write.csv(phyla_pvalues, "~/CursoR/CursoRgit/Agronomia/Materiales/phyla_pvalues.csv")
```

Basados en estos resultados se concluye que Proteobacteria si presenta marginalmente diferencias estadisticas en cuanto al tratamiento, mientras que WPS2 y bacteroidota presentan diferencias significativas para la variable de muestreo.


```{r}
load("Bio.RData")

# Por diferencias
Firmi <- subset_taxa(Bio, Phylum == "Firmicutes")

Chloro <- subset_taxa(Bio, Phylum == "Chloroflexi")

# Por abundancias
Proteo <- subset_taxa(Bio, Phylum == "Proteobacteria")

Actino <- subset_taxa(Bio, Phylum == "Actinobacteriota")
```

# 2. Visualiar a nivel de orden

Si bien despues de phylum viene clase, por razones de tiempo(tanto de la clase como de su trabajo) les recomiendo que el siguiente nivel a analizar sea orden:

```{r}
# Por diferencias
Firmi_ord <- tax_glom(Firmi,taxrank = "Order", NArm = FALSE)
Chloro_ord <- tax_glom(Chloro,taxrank = "Order", NArm = FALSE)

# Por abundancias
Proteo_ord <- tax_glom(Proteo, taxrank = "Order", NArm = FALSE)
Actino_ord <- tax_glom(Actino, taxrank = "Order", NArm = FALSE)
```

```{r}
# Por diferencias:
plot_composition(Chloro_ord, plot.type = "barplot")+ 
  theme_bw()+
  ggtitle("Abundancias de Chloroflexi a nivel Orden")+
  theme(plot.title = element_text(hjust = 0.5, size = 15, face = "bold"))+
  scale_x_discrete(labels=c("Tratado 1ro", "Tratado 2do", "Tratado 3ro","Testigo 3ro", "Testigo 1ro", "Testigo 2do"))+
  xlab("Muestras")+
  ylab("Abundancia")

plot_composition(Firmi_ord, plot.type = "barplot")+ 
  theme_bw()+
  ggtitle("Abundancias de Firmicutes a nivel Orden")+
  scale_x_discrete(labels=c("Tratado 1ro", "Tratado 2do", "Tratado 3ro","Testigo 3ro", "Testigo 1ro", "Testigo 2do"))+
  theme(plot.title = element_text(hjust = 0.5, size = 15, face = "bold"))+
  xlab("Muestras")+
  ylab("Abundancia")

# Por abundancias:
plot_composition(Proteo_ord, plot.type = "barplot")+
  theme_bw()+
  ggtitle("Abundancias de Proteobacteria a nivel Orden")+
  scale_x_discrete(labels=c("Tratado 1ro", "Tratado 2do", "Tratado 3ro", "Testigo 3ro", "Testigo 1ro", "Testigo 2do"))+
  theme(plot.title = element_text(hjust = 0.5, size = 15, face = "bold"))+
  xlab("Muestras")+
  ylab("Abundancia")

plot_composition(Actino_ord, plot.type = "barplot")+
  theme_bw()+
  ggtitle("Abundancias de Actinobacteriota a nivel Orden")+
  scale_x_discrete(labels=c("Tratado 1ro", "Tratado 2do", "Tratado 3ro", "Testigo 3ro", "Testigo 1ro", "Testigo 2do"))+
  theme(plot.title = element_text(hjust = 0.5, size = 15, face = "bold"))+
  xlab("Muestras")+
  ylab("Abundancia")
```
```{r}
# Heatmap con microbiome
plot_composition(Chloro_ord, plot.type = "heatmap")+
  theme_bw()+
  coord_flip()
# Si tenemos muhas muestras es mejor usar barplot porque pude morir la compu

# Usando la funcion de phyloseq para los graficos de diferencias
plot_heatmap(Chloro_ord, 
             low = "lightskyblue", high = "#0F0F43",
             na.value = "snow2",
             taxa.order = names(sort(taxa_sums(Chloro_ord))))

plot_heatmap(Firmi_ord, 
             low = "lightskyblue", high = "#0F0F43",
             na.value = "snow2",
             taxa.order = names(sort(taxa_sums(Firmi_ord))))

# Usando la funcion de phyloseq para los graficos de abundancia
plot_heatmap(Actino_ord,
             low = "lightskyblue", high = "#0F0F43",
             na.value = "snow2",
             taxa.order = names(sort(taxa_sums(Actino_ord))))

plot_heatmap(Proteo_ord,
             low = "lightskyblue", high = "#0F0F43",
             na.value = "snow2",
             taxa.order = names(sort(taxa_sums(Proteo_ord))))

```

## Análisis estadistico a nivel orden

```{r}
load("Bio.RData")

# Analisis estadistico de Proteobacteria por abundancias
OTU_matrix <- as.data.frame(Proteo_ord@otu_table)
Tax_matrix <- as.data.frame(Proteo_ord@tax_table)

metadata <- as.data.frame(Proteo_ord@sam_data)

## Renombramos las columnas de nuestras abundancias con el phylum de la tabla de taxa
colnames(OTU_matrix) <- Tax_matrix$Order 
OTU_matrix <- OTU_matrix[,-3]

Bio_order <- cbind(metadata,OTU_matrix)

## Revisar normalizacion:

for(i in 3:ncol(Bio_order)){
  shapiro <- shapiro.test(Bio_order[,i])
  normal <- ifelse(shapiro[["p.value"]]>0.05, "YES", "NO")
  print(c(i,normal))
}

Norm_bio <- Bio_order[,c(5,7,9,14)]

for(i in 1:ncol(Norm_bio)){
  Norm_bio[,i] <- abs(log10(Norm_bio[,i]+1)) 
}

for(i in 1:ncol(Norm_bio)){
  shapiro <- shapiro.test(Norm_bio[,i])
  normal <- ifelse(shapiro[["p.value"]]>0.05, "YES", "NO")
  print(c(i,normal))
}

bio_stats <- cbind(Bio_order[,-c(5:7,9:10,12,14,15:20)],Norm_bio)

order_pvalues <- data.frame(Tratamiento = rep(NA,9),
                            Muestreo = rep(NA,9))

for(i in 3:ncol(bio_stats)){
  T_trat <- t.test(bio_stats[,i]~Tratamiento, data=bio_stats)
  M_trat <- Anova(aov(bio_stats[,i]~Muestreo, data=bio_stats))
  j <- i-2 # esto es para que empiece a llenar desde la fila 1 
  order_pvalues$Tratamiento[j] <- T_trat[["p.value"]]
  order_pvalues$Muestreo[j] <- M_trat$`Pr(>F)`[1]
}

row.names(order_pvalues) <- colnames(bio_stats[3:11])

# Se guarda esta tabla
write.csv(order_pvalues, "~/CursoR/CursoRgit/Agronomia/Materiales/order_pvalues.csv")


# Analisis estadistico de Firmicutes por diferencia
OTU_matrix <- as.data.frame(Firmi_ord@otu_table)
Tax_matrix <- as.data.frame(Firmi_ord@tax_table)

metadata <- as.data.frame(Firmi_ord@sam_data)

## Renombramos las columnas de nuestras abundancias con el phylum de la tabla de taxa
colnames(OTU_matrix) <- Tax_matrix$Order 
OTU_matrix <- OTU_matrix[,-1]

Bio_order <- cbind(metadata,OTU_matrix)

## Revisar normalizacion:

for(i in 3:ncol(Bio_order)){
  shapiro <- shapiro.test(Bio_order[,i])
  normal <- ifelse(shapiro[["p.value"]]>0.05, "YES", "NO")
  print(c(i,normal))
}

Norm_bio <- Bio_order[,c(5,7,9,14)]

for(i in 1:ncol(Norm_bio)){
  Norm_bio[,i] <- abs(log10(Norm_bio[,i]+1)) 
}

for(i in 1:ncol(Norm_bio)){
  shapiro <- shapiro.test(Norm_bio[,i])
  normal <- ifelse(shapiro[["p.value"]]>0.05, "YES", "NO")
  print(c(i,normal))
}

bio_stats <- cbind(Bio_order[,-c(5:7,9:10,12,14,15:20)],Norm_bio)

order_pvalues <- data.frame(Tratamiento = rep(NA,9),
                            Muestreo = rep(NA,9))

for(i in 3:ncol(bio_stats)){
  T_trat <- t.test(bio_stats[,i]~Tratamiento, data=bio_stats)
  M_trat <- Anova(aov(bio_stats[,i]~Muestreo, data=bio_stats))
  j <- i-2 # esto es para que empiece a llenar desde la fila 1 
  order_pvalues$Tratamiento[j] <- T_trat[["p.value"]]
  order_pvalues$Muestreo[j] <- M_trat$`Pr(>F)`[1]
}

row.names(order_pvalues) <- colnames(bio_stats[3:11])

# Se guarda esta tabla
write.csv(order_pvalues, "~/CursoR/CursoRgit/Agronomia/Materiales/order_pvalues.csv")
```

## Análisis a nivel de genero